{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "52cc8b84",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tqdm import tqdm\n",
    "import PIL\n",
    "from PIL import Image\n",
    "from PIL import Image, ImageDraw, ImageOps\n",
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "78a0a074",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model('./saved_model',compile=False)\n",
    "image_size = 75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c866f4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test = pd.read_csv('./test_data/test.txt', header = None, sep = '\\t', names = [\"image\", \"label\"])\n",
    "\n",
    "# for img_name in tqdm(test['image']):\n",
    "#     path = './test_data/test_images/'+str(img_name)\n",
    "#     with PIL.Image.open(path) as img:\n",
    "#         width, height = img.size\n",
    "#         left_half = (0, 0, width//4,height)\n",
    "#         img = img.crop(left_half)\n",
    "#         img = img.resize((299,299))\n",
    "#         img.save(f'./{\"resize_test\"}/{img_name}') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "afb26533",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████| 98/98 [00:00<00:00, 290.88it/s]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os.path\n",
    "import pandas as pd\n",
    "import PIL\n",
    "import urllib.request\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Define the URL and local filename of the Haar Cascade classifier file\n",
    "url = 'https://raw.githubusercontent.com/opencv/opencv/master/data/haarcascades/haarcascade_frontalface_default.xml'\n",
    "local_file = 'haar_cascade/haarcascade_frontalface_default.xml'\n",
    "\n",
    "# Download the Haar Cascade classifier file if it doesn't exist\n",
    "if not os.path.exists(local_file):\n",
    "    urllib.request.urlretrieve(url, local_file)\n",
    "\n",
    "# Load the face detection classifier\n",
    "face_cascade = cv2.CascadeClassifier(local_file)\n",
    "\n",
    "# Load the test data\n",
    "test = pd.read_csv('./test_data/test.txt', header=None, sep='\\t', names=['image', 'label'])\n",
    "\n",
    "# Define a function to detect and crop faces from an image\n",
    "def detect_and_crop_faces(image_path):\n",
    "    with PIL.Image.open(image_path) as img:\n",
    "        # Crop the left half of the image\n",
    "        width, height = img.size\n",
    "        left_half = (0, 0, width//4, height)\n",
    "        img = img.crop(left_half)\n",
    "        \n",
    "        # Convert the image to grayscale\n",
    "        gray = cv2.cvtColor(np.array(img), cv2.COLOR_RGB2GRAY)\n",
    "        \n",
    "        # Detect faces in the image\n",
    "        faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "        \n",
    "        # Get the face closest to the center of the image\n",
    "        center_x, center_y = img.size[0] // 2, img.size[1] // 2\n",
    "        closest_face = None\n",
    "        closest_distance = float('inf')\n",
    "        for (x, y, w, h) in faces:\n",
    "            distance = ((x + w // 2) - center_x) ** 2 + ((y + h // 2) - center_y) ** 2\n",
    "            if distance < closest_distance:\n",
    "                closest_face = (x, y, w, h)\n",
    "                closest_distance = distance\n",
    "        \n",
    "        # Crop and resize the closest face\n",
    "        if closest_face is not None:\n",
    "            (x, y, w, h) = closest_face\n",
    "            # Crop the face\n",
    "            face_img = img.crop((x, y, x+w, y+h))\n",
    "            \n",
    "            # Resize the face to a specific size\n",
    "            resized_face = face_img.resize((299, 299))\n",
    "            \n",
    "            # Save the cropped and resized face\n",
    "            return resized_face\n",
    "\n",
    "# Loop over each image in the test set and detect and crop faces\n",
    "for img_name in tqdm(test['image']):\n",
    "    # Load the image\n",
    "    path = './test_data/test_images/' + str(img_name)\n",
    "    \n",
    "    # Detect and crop faces from the image\n",
    "    cropped_faces = detect_and_crop_faces(path)\n",
    "    \n",
    "    # Save the cropped faces\n",
    "    if cropped_faces is not None:\n",
    "        cropped_faces.save(f'./{\"resize_test\"}/{img_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "6dec62ef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 16 validated image filenames.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vh/.local/lib/python3.11/site-packages/keras/preprocessing/image.py:1137: UserWarning: Found 82 invalid image filename(s) in x_col=\"image\". These filename(s) will be ignored.\n",
      "  warnings.warn(\n",
      "2023-05-14 14:33:01.365676: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n"
     ]
    }
   ],
   "source": [
    "# test['image'] = test['image'].str.replace('.jpg', '.png')\n",
    "\n",
    "datagen = keras.preprocessing.image.ImageDataGenerator(rescale=1/255.0,\n",
    "                                                        preprocessing_function=None,\n",
    "                                                        data_format=None,\n",
    "                                                    )\n",
    "test_data = datagen.flow_from_dataframe(\n",
    "    test,\n",
    "    directory = './resize_test',\n",
    "    x_col=\"image\",\n",
    "    y_col= None,\n",
    "    color_mode=\"rgb\",\n",
    "    target_size = (image_size,image_size),\n",
    "    classes=None,\n",
    "    class_mode=None,\n",
    "    batch_size=32,\n",
    "    shuffle=False,\n",
    "    seed=40,\n",
    ")\n",
    "\n",
    "preds = model.predict(test_data)\n",
    "# print(preds)\n",
    "preds = preds.tolist()\n",
    "\n",
    "indices = []\n",
    "for pred in preds:\n",
    "#     print(pred)\n",
    "    max_pred= 0.0\n",
    "    temp = []\n",
    "    for category in pred:\n",
    "        if category>max_pred:\n",
    "#             temp.append(pred.index(category))\n",
    "#             break\n",
    "            max_pred = category\n",
    "    temp.append(pred.index(max_pred))\n",
    "    if temp!=[]:\n",
    "        indices.append(temp)\n",
    "    else:\n",
    "        temp.append(np.argmax(pred))\n",
    "        indices.append(temp)\n",
    "\n",
    "# print(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "41d357dc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 64 validated image filenames belonging to 64 classes.\n",
      "{0: 'Ahri', 1: 'Akali', 2: 'Alistar', 3: 'Amumu', 4: 'Annie', 5: 'Ashe', 6: 'AurelionSol', 7: 'Blitzcrank', 8: 'Braum', 9: 'Camille', 10: 'Corki', 11: 'Darius', 12: 'Diana', 13: 'DrMundo', 14: 'Draven', 15: 'Evelynn', 16: 'Ezreal', 17: 'Fiora', 18: 'Fizz', 19: 'Galio', 20: 'Garen', 21: 'Gragas', 22: 'Graves', 23: 'Janna', 24: 'JarvanIV', 25: 'Jax', 26: 'Jhin', 27: 'Jinx', 28: 'Kaisa', 29: 'Katarina', 30: 'Kennen', 31: 'Khazix', 32: 'LeeSin', 33: 'Leona', 34: 'Lulu', 35: 'Lux', 36: 'Malphite', 37: 'MasterYi', 38: 'MissFortune', 39: 'MonkeyKing', 40: 'Nami', 41: 'Nasus', 42: 'Olaf', 43: 'Orianna', 44: 'Pantheon', 45: 'Rakan', 46: 'Rammus', 47: 'Rengar', 48: 'Seraphine', 49: 'Shyvana', 50: 'Singed', 51: 'Sona', 52: 'Soraka', 53: 'Teemo', 54: 'Tristana', 55: 'Tryndamere', 56: 'TwistedFate', 57: 'Varus', 58: 'Vayne', 59: 'Vi', 60: 'XinZhao', 61: 'Yasuo', 62: 'Zed', 63: 'Ziggs'}\n",
      "['Amumu', 'Kaisa', 'Amumu', 'Amumu', 'MonkeyKing', 'MonkeyKing', 'Janna', 'Amumu', 'Ezreal', 'Amumu', 'Amumu', 'Kaisa', 'MonkeyKing', 'MonkeyKing', 'Ezreal', 'Ezreal']\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('train.csv', header=None, names=[\"image\", \"labels\"])\n",
    "train_data = datagen.flow_from_dataframe(\n",
    "    train,\n",
    "    directory='./train_dataset',\n",
    "    x_col=\"image\",\n",
    "    y_col= 'labels',\n",
    "    color_mode=\"rgb\",\n",
    "    target_size = (image_size,image_size),\n",
    "    class_mode=\"categorical\",\n",
    "    batch_size=4,\n",
    "    shuffle=False,\n",
    "    seed=40,\n",
    ")\n",
    "labels = (train_data.class_indices)\n",
    "labels = dict((v,k) for k,v in labels.items())\n",
    "print(labels)\n",
    "\n",
    "testlabels = []\n",
    "\n",
    "\n",
    "for image in indices:\n",
    "    temp = []\n",
    "    for i in image:\n",
    "        temp.append(str(labels[i]))\n",
    "    testlabels.append(' '.join(temp))\n",
    "\n",
    "print(testlabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "0a5d8742",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length of values (16) does not match length of index (98)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [75], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtest\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpredict\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m testlabels\n\u001b[1;32m      2\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(test)\n\u001b[1;32m      3\u001b[0m df\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/pandas/core/frame.py:3980\u001b[0m, in \u001b[0;36mDataFrame.__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3977\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setitem_array([key], value)\n\u001b[1;32m   3978\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3979\u001b[0m     \u001b[38;5;66;03m# set column\u001b[39;00m\n\u001b[0;32m-> 3980\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_set_item\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/pandas/core/frame.py:4174\u001b[0m, in \u001b[0;36mDataFrame._set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   4164\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_set_item\u001b[39m(\u001b[38;5;28mself\u001b[39m, key, value) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   4165\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4166\u001b[0m \u001b[38;5;124;03m    Add series to DataFrame in specified column.\u001b[39;00m\n\u001b[1;32m   4167\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4172\u001b[0m \u001b[38;5;124;03m    ensure homogeneity.\u001b[39;00m\n\u001b[1;32m   4173\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4174\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sanitize_column\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4176\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   4177\u001b[0m         key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[1;32m   4178\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m value\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   4179\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_extension_array_dtype(value)\n\u001b[1;32m   4180\u001b[0m     ):\n\u001b[1;32m   4181\u001b[0m         \u001b[38;5;66;03m# broadcast across multiple columns if necessary\u001b[39;00m\n\u001b[1;32m   4182\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mis_unique \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns, MultiIndex):\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/pandas/core/frame.py:4915\u001b[0m, in \u001b[0;36mDataFrame._sanitize_column\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m   4912\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _reindex_for_setitem(Series(value), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex)\n\u001b[1;32m   4914\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_list_like(value):\n\u001b[0;32m-> 4915\u001b[0m     \u001b[43mcom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequire_length_match\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4916\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m sanitize_array(value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, allow_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/pandas/core/common.py:571\u001b[0m, in \u001b[0;36mrequire_length_match\u001b[0;34m(data, index)\u001b[0m\n\u001b[1;32m    567\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    568\u001b[0m \u001b[38;5;124;03mCheck the length of data matches the length of the index.\u001b[39;00m\n\u001b[1;32m    569\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    570\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(index):\n\u001b[0;32m--> 571\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    572\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLength of values \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    573\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(data)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    574\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdoes not match length of index \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    575\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(index)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    576\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Length of values (16) does not match length of index (98)"
     ]
    }
   ],
   "source": [
    "test['predict'] = testlabels\n",
    "df = pd.DataFrame(test)\n",
    "df.to_csv('test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce09ee9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
